{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ebb5f7",
   "metadata": {},
   "source": [
    "# Speech recognition with noise analysis\n",
    "\n",
    "This notebook implements a speech recognition system with balanced dataset handling and improved model architecture to ensure equal performance across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b182ba",
   "metadata": {},
   "source": [
    "## 1. Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from IPython.display import Audio, display\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Constants\n",
    "DATA_PATH = \"sound\"\n",
    "WORDS = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION = 1\n",
    "N_MELS = 128\n",
    "FIXED_SHAPE = (128, 32)\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d0137",
   "metadata": {},
   "source": [
    "## 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_white_noise(signal, snr_db):\n",
    "    \"\"\"Add white Gaussian noise at a given SNR (dB)\"\"\"\n",
    "    rms_signal = np.sqrt(np.mean(signal**2))\n",
    "    snr_linear = 10**(snr_db / 10)\n",
    "    rms_noise = rms_signal / np.sqrt(snr_linear)\n",
    "    noise = np.random.normal(0, rms_noise, signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "def mix_background_noise(signal, noise, snr_db):\n",
    "    \"\"\"Mix background noise at a given SNR (dB)\"\"\"\n",
    "    if len(noise) < len(signal):\n",
    "        noise = np.tile(noise, int(np.ceil(len(signal) / len(noise))))\n",
    "    noise = noise[:len(signal)]\n",
    "    rms_signal = np.sqrt(np.mean(signal**2))\n",
    "    snr_linear = 10**(snr_db / 10)\n",
    "    rms_noise = rms_signal / np.sqrt(snr_linear)\n",
    "    noise = noise / np.sqrt(np.mean(noise**2)) * rms_noise\n",
    "    return signal + noise\n",
    "\n",
    "def pad_or_truncate(mel_db, target_shape):\n",
    "    \"\"\"Pad or truncate a mel spectrogram to target shape\"\"\"\n",
    "    padded = np.zeros(target_shape)\n",
    "    h, w = mel_db.shape\n",
    "    h_target, w_target = target_shape\n",
    "    h = min(h, h_target)\n",
    "    w = min(w, w_target)\n",
    "    padded[:h, :w] = mel_db[:h, :w]\n",
    "    return padded\n",
    "\n",
    "def plot_mel_spectrogram(signal, sr, title):\n",
    "    \"\"\"Plot mel spectrogram\"\"\"\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=N_MELS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_db, sr=sr, x_axis='time', y_axis='mel', vmin=-80, vmax=0)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1ac49",
   "metadata": {},
   "source": [
    "## 3. Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054743e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check dataset balance\n",
    "print(\"Checking dataset distribution:\")\n",
    "samples_per_word = {}\n",
    "for word in WORDS:\n",
    "    word_path = os.path.join(DATA_PATH, word)\n",
    "    if not os.path.exists(word_path):\n",
    "        print(f\"Warning: No folder found for '{word}'\")\n",
    "        continue\n",
    "    files = [f for f in os.listdir(word_path) if f.endswith('.wav')]\n",
    "    samples_per_word[word] = len(files)\n",
    "    print(f\"{word}: {len(files)} files\")\n",
    "\n",
    "# Find minimum number of samples across classes for balancing\n",
    "# min_samples = min(samples_per_word.values())\n",
    "min_samples = 100  # Set a fixed number for balancing\n",
    "print(f\"\\nUsing {min_samples} samples per class for balance\")\n",
    "\n",
    "# Load background noise\n",
    "bg_noise_path = os.path.join(DATA_PATH, \"_background_noise_\", \"doing_the_dishes.wav\")\n",
    "bg_noise, _ = librosa.load(bg_noise_path, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y_raw = []\n",
    "test_files = []\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(WORDS)\n",
    "\n",
    "for word in WORDS:\n",
    "    word_path = os.path.join(DATA_PATH, word)\n",
    "    files = [f for f in os.listdir(word_path) if f.endswith('.wav')][:min_samples]  # Take exactly 100 files per word\n",
    "\n",
    "    signals = []\n",
    "    labels = []\n",
    "    paths = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(word_path, file)\n",
    "        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "        signals.append(signal)\n",
    "        labels.append(word)\n",
    "        paths.append(file_path)\n",
    "\n",
    "    # Split 80/20 train/test\n",
    "    sig_train, sig_test, lab_train, lab_test, path_train, path_test = train_test_split(\n",
    "        signals, labels, paths, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Process training data with augmentation (uncomment if the training will be done with noise)\n",
    "    for signal in sig_train:\n",
    "        variants = [\n",
    "            signal\n",
    "            # ,\n",
    "            # add_white_noise(signal, 40),\n",
    "            # add_white_noise(signal, 20),\n",
    "            # mix_background_noise(signal, bg_noise, 40),\n",
    "            # mix_background_noise(signal, bg_noise, 20)\n",
    "        ]\n",
    "\n",
    "        for variant in variants:\n",
    "            mel = librosa.feature.melspectrogram(y=variant, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "            mel_fixed = pad_or_truncate(mel_db, FIXED_SHAPE)\n",
    "            X.append(mel_fixed)\n",
    "            y_raw.append(word)\n",
    "\n",
    "    # Save test files\n",
    "    for p, l in zip(path_test, lab_test):\n",
    "        test_files.append((p, l))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)[..., np.newaxis]\n",
    "y_encoded = le.transform(y_raw)\n",
    "y = to_categorical(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40539156",
   "metadata": {},
   "source": [
    "## 4. Model architecture and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68562cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(WORDS), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f669377",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a54060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "X_clean = []\n",
    "y_clean = []\n",
    "\n",
    "for file_path, label_str in test_files:\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "    mel = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=N_MELS)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel_fixed = pad_or_truncate(mel_db, FIXED_SHAPE)\n",
    "    X_clean.append(mel_fixed)\n",
    "    y_clean.append(label_str)\n",
    "\n",
    "X_clean = np.array(X_clean)[..., np.newaxis]\n",
    "y_encoded = le.transform(y_clean)\n",
    "y_test = to_categorical(y_encoded)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_clean)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix (Clean Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot per-class accuracy\n",
    "accuracies = []\n",
    "for i, word in enumerate(le.classes_):\n",
    "    idx = np.where(y_true == i)[0]\n",
    "    acc = accuracy_score(y_true[idx], y_pred[idx])\n",
    "    accuracies.append(acc)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(le.classes_, accuracies, color='skyblue')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per Word (Clean Test Set)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd7877",
   "metadata": {},
   "source": [
    "## 6. Noise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_files_with_noise(noise_fn, snr_db, label=\"\"):\n",
    "    X_noise = []\n",
    "    y_noise = []\n",
    "\n",
    "    for file_path, label_str in test_files:\n",
    "        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "        noisy = noise_fn(signal, snr_db)\n",
    "        mel = librosa.feature.melspectrogram(y=noisy, sr=sr, n_mels=N_MELS)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_fixed = pad_or_truncate(mel_db, FIXED_SHAPE)\n",
    "        X_noise.append(mel_fixed)\n",
    "        y_noise.append(label_str)\n",
    "\n",
    "    X_noise = np.array(X_noise)[..., np.newaxis]\n",
    "    y_encoded = le.transform(y_noise)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "    y_pred_probs = model.predict(X_noise)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_categorical, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy on test set ({label}): {acc:.3f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "    disp.plot(xticks_rotation=45)\n",
    "    plt.title(f\"Confusion Matrix ({label})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return acc\n",
    "\n",
    "# Run evaluations\n",
    "acc_clean = evaluate_test_files_with_noise(lambda x, _: x, 0, \"Clean Audio\")\n",
    "acc_white_40 = evaluate_test_files_with_noise(add_white_noise, 40, \"White Noise 40dB\")\n",
    "acc_white_20 = evaluate_test_files_with_noise(add_white_noise, 20, \"White Noise 20dB\")\n",
    "acc_bg_40 = evaluate_test_files_with_noise(lambda x, snr: mix_background_noise(x, bg_noise, snr), 40, \"Background Noise 40dB\")\n",
    "acc_bg_20 = evaluate_test_files_with_noise(lambda x, snr: mix_background_noise(x, bg_noise, snr), 20, \"Background Noise 20dB\")\n",
    "\n",
    "noise_labels = [\"Clean\", \"White 40dB\", \"White 20dB\", \"BG 40dB\", \"BG 20dB\"]\n",
    "noise_accuracies = [acc_clean, acc_white_40, acc_white_20, acc_bg_40, acc_bg_20]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(noise_labels, noise_accuracies, color='salmon')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Performance on Noisy Test WAV Files\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d869c",
   "metadata": {},
   "source": [
    "## 7. Audio Examples and Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd332f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process example audio\n",
    "yes_path = os.path.join(DATA_PATH, \"yes\", os.listdir(os.path.join(DATA_PATH, \"yes\"))[0])\n",
    "y_yes, sr = librosa.load(yes_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "# Generate noisy versions\n",
    "y_white_40 = add_white_noise(y_yes, 40)\n",
    "y_white_20 = add_white_noise(y_yes, 20)\n",
    "y_bg_40 = mix_background_noise(y_yes, bg_noise, 40)\n",
    "y_bg_20 = mix_background_noise(y_yes, bg_noise, 20)\n",
    "\n",
    "# Play audio samples\n",
    "print(\"🔊 Original Audio:\")\n",
    "display(Audio(y_yes, rate=sr))\n",
    "\n",
    "print(\"\\n🔊 40 dB White Gaussian Noise:\")\n",
    "display(Audio(y_white_40, rate=sr))\n",
    "\n",
    "print(\"\\n🔊 20 dB White Gaussian Noise:\")\n",
    "display(Audio(y_white_20, rate=sr))\n",
    "\n",
    "print(\"\\n🔊 40 dB Background Noise (doing_the_dishes.wav):\")\n",
    "display(Audio(y_bg_40, rate=sr))\n",
    "\n",
    "print(\"\\n🔊 20 dB Background Noise (doing_the_dishes.wav):\")\n",
    "display(Audio(y_bg_20, rate=sr))\n",
    "\n",
    "# Plot spectrograms\n",
    "plot_mel_spectrogram(y_yes, sr, \"Mel Spectrogram - Original 'yes'\")\n",
    "plot_mel_spectrogram(y_white_40, sr, \"Mel Spectrogram - 'yes' with 40 dB White Noise\")\n",
    "plot_mel_spectrogram(y_white_20, sr, \"Mel Spectrogram - 'yes' with 20 dB White Noise\")\n",
    "plot_mel_spectrogram(y_bg_40, sr, \"Mel Spectrogram - 'yes' with 40 dB Background Noise\")\n",
    "plot_mel_spectrogram(y_bg_20, sr, \"Mel Spectrogram - 'yes' with 20 dB Background Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac9980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98179d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
